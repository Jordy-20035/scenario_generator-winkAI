# Заявка на получение вычислительных ресурсов

**Трек:** Платформа автоматического разбора и структурирования сценариев  
**Команда:** DiverCity  
**Участник:** [Ваше имя]  
**Дата:** [указать дату подачи]

---

## 1. Краткое описание текущего состояния проекта

Реализован базовый функционал для обработки сценариев: парсинг PDF/DOCX, простые алгоритмы сегментации сцен и извлечения элементов на основе ключевых слов. Создан интерфейс с возможностью множественной загрузки файлов и генерации таблиц с выбором пресетов. Для повышения точности и полноты извлечения требуется разработка и обучение специализированных ML-моделей, что является основной задачей на следующих этапах работы.

---

## 2. План работ

### Этап 1: Подготовка данных и baseline (Неделя 1-2)
- **Задачи:**
  - Анализ предоставленных организаторами образцов сценариев и препродакшн-таблиц
  - Разметка обучающих данных (выделение персонажей, локаций, реквизита, спецэффектов)
  - Создание baseline метрик для оценки качества извлечения
  - Подготовка и предобработка корпуса сценариев для обучения моделей

### Этап 2: Разработка и обучение ML-моделей (Неделя 3-6, с использованием GPU)
- **Задачи:**
  - **Обучение NER-модели для извлечения именованных сущностей:**
    - Персонажи (имена с учетом различных вариантов написания)
    - Локации (объекты и подобъекты)
    - Названия реквизита и спецоборудования
    - Планируемое использование GPU: ~15 часов
  
  - **Обучение классификаторов:**
    - Определение времени суток (утро/день/вечер/ночь)
    - Классификация интерьер/экстерьер
    - Определение наличия массовки, спецэффектов, каскадеров
    - Планируемое использование GPU: ~10 часов
  
  - **Fine-tuning языковой модели:**
    - Адаптация для понимания специфики кинематографических сценариев
    - Извлечение контекстной информации (грим, костюм, декорации)
    - Планируемое использование GPU: ~10 часов

### Этап 3: Интеграция моделей и оптимизация (Неделя 7-8)
- **Задачи:**
  - Интеграция обученных моделей в существующую архитектуру
  - Оптимизация производительности (обеспечение обработки в пределах 5 минут)
  - Тестирование на реальных сценариях (6 серий от организаторов)
  - Исправление ошибок и неточностей извлечения

### Этап 4: Улучшение пользовательского опыта (Неделя 9)
- **Задачи:**
  - Расширение функциональности интерфейса
  - Добавление возможности ручной корректировки извлеченных данных
  - Улучшение визуализации результатов
  - Подготовка демо-видео и презентации

### Этап 5: Финальная доработка и тестирование (Неделя 10)
- **Задачи:**
  - Тестирование на дополнительном сценарии от организаторов
  - Генерация финальной препродакшн-таблицы
  - Документирование решения
  - Подготовка к демонстрации

**Общий срок выполнения:** 10 недель

---

## 3. Распределение ролей в команде

**Команда состоит из одного участника**, выполняющего все роли:

- **Backend Developer:** Разработка и поддержка backend-модулей (FastAPI)
- **ML Engineer:** Исследование, обучение и интеграция ML-моделей
- **Frontend Developer:** Разработка и улучшение пользовательского интерфейса (Streamlit)
- **Data Engineer:** Подготовка данных, разметка, валидация
- **QA/Testing:** Тестирование функциональности и качества извлечения

---

## 4. Использование GPU ресурсов

### Планируемое использование GPU L4 (40 часов):

1. **Обучение NER-модели для русского языка:**
   - Fine-tuning предобученной модели (ruBERT/DeBERTa)
   - Обучение на размеченных сценариях
   - Валидация и оценка качества
   - **Время:** ~15 часов

2. **Обучение классификаторов:**
   - Модели для определения времени суток, интерьер/экстерьер
   - Классификаторы для категорий производственных элементов
   - Оптимизация гиперпараметров
   - **Время:** ~10 часов

3. **Fine-tuning языковой модели:**
   - Адаптация для кинематографической специфики
   - Контекстное извлечение сложных элементов (грим, костюм)
   - Обработка неоднозначных формулировок
   - **Время:** ~10 часов

4. **Валидация и тестирование:**
   - Тестирование на различных типах сценариев
   - Сравнение с baseline алгоритмами
   - Оценка метрик качества
   - **Время:** ~3 часа

5. **Резерв:**
   - Непредвиденные эксперименты и доработки
   - **Время:** ~2 часа

**Общая потребность:** 40 часов

### Ожидаемые результаты после использования GPU:

- **Точность извлечения персонажей:** с текущих ~50-60% до целевых **85-90%**
- **Точность извлечения локаций:** с текущих ~60-70% до целевых **90-95%**
- **Распознавание реквизита:** с текущих ~40-50% до целевых **80-85%**
- **Определение времени суток:** с текущих ~70% до целевых **95%+**
- **Извлечение спецэффектов и оборудования:** новый функционал с точностью **75-80%**
- **Снижение ложных срабатываний:** на **50-60%**

---

## 5. Технический стек для ML-разработки

- **Язык:** Python 3.11
- **ML фреймворки:** PyTorch, Transformers (Hugging Face)
- **Модели:** ruBERT-base, DeBERTa для русского языка
- **Библиотеки:** spaCy (baseline), scikit-learn (классификация)
- **Инфраструктура:** Yandex Cloud GPU (L4 24GB)
- **Версионирование:** GitLab (предоставленный организаторами репозиторий)

---

## 6. Ключевые задачи для решения с помощью ML

### Приоритет 1: Критические улучшения
1. **Точное извлечение персонажей** — текущий keyword-based подход пропускает многие имена
2. **Определение локаций с контекстом** — улучшение распознавания объектов и подобъектов
3. **Извлечение реквизита** — автоматическое распознавание всех упомянутых предметов

### Приоритет 2: Новый функционал
4. **Извлечение грима и костюмов** — не реализовано, требуется ML-подход
5. **Определение каскадеров и пиротехники** — не реализовано
6. **Извлечение декораций** — не реализовано

### Приоритет 3: Улучшение качества
7. **Обработка опечаток и неоднозначностей** — повышение устойчивости к ошибкам в исходных сценариях
8. **Контекстное понимание** — улучшение точности за счет анализа окружающего текста

---

## 7. Риски и их митигация

- **Риск:** Недостаточно размеченных данных для обучения
  - **Митигация:** Использование полу-обучения, data augmentation, transfer learning от предобученных моделей

- **Риск:** Модели не укладываются в ограничение 80GB VRAM
  - **Митигация:** Использование более легких архитектур, quantization, batch processing

- **Риск:** Время обработки превышает 5 минут
  - **Митигация:** Оптимизация inference, кэширование, батчинг запросов

---

**Контактное лицо:** [Ваше имя]  
**Email:** [Ваш email]  
**Репозиторий:** [URL вашего GitLab репозитория]

---

*Документ подготовлен участником команды DiverCity для получения вычислительных ресурсов от организаторов конкурса winkAI.*
